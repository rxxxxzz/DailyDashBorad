[
  {
    "name": "native-sparse-attention-pytorch",
    "full_name": "lucidrains/native-sparse-attention-pytorch",
    "description": "Implementation of the sparse attention pattern proposed by the Deepseek team in their \"Native Sparse Attention\" paper",
    "url": "https://github.com/lucidrains/native-sparse-attention-pytorch",
    "stars": 409,
    "daily_stars": 2,
    "language": "Python",
    "topics": [
      "artificial-intelligence",
      "attention",
      "deep-learning"
    ],
    "created_at": "2025-02-19T03:37:52",
    "updated_at": "2025-02-23T06:06:27"
  },
  {
    "name": "native-sparse-attention-pytorch",
    "full_name": "lucidrains/native-sparse-attention-pytorch",
    "description": "Implementation of the sparse attention pattern proposed by the Deepseek team in their \"Native Sparse Attention\" paper",
    "url": "https://github.com/lucidrains/native-sparse-attention-pytorch",
    "stars": 409,
    "daily_stars": 0,
    "language": "Python",
    "topics": [
      "artificial-intelligence",
      "attention",
      "deep-learning"
    ],
    "created_at": "2025-02-19T03:37:52",
    "updated_at": "2025-02-23T06:06:27"
  },
  {
    "name": "deep-cross-attention",
    "full_name": "lucidrains/deep-cross-attention",
    "description": "Implementation of the proposed DeepCrossAttention by Heddes et al while at Google research, in Pytorch",
    "url": "https://github.com/lucidrains/deep-cross-attention",
    "stars": 71,
    "daily_stars": 0,
    "language": null,
    "topics": [
      "artificial-intelligence",
      "attention-mechanism",
      "deep-learning",
      "residuals",
      "transformers"
    ],
    "created_at": "2025-02-18T15:28:43",
    "updated_at": "2025-02-21T14:36:47"
  },
  {
    "name": "deep-cross-attention",
    "full_name": "lucidrains/deep-cross-attention",
    "description": "Implementation of the proposed DeepCrossAttention by Heddes et al while at Google research, in Pytorch",
    "url": "https://github.com/lucidrains/deep-cross-attention",
    "stars": 71,
    "daily_stars": 0,
    "language": null,
    "topics": [
      "artificial-intelligence",
      "attention-mechanism",
      "deep-learning",
      "residuals",
      "transformers"
    ],
    "created_at": "2025-02-18T15:28:43",
    "updated_at": "2025-02-21T14:36:47"
  },
  {
    "name": "A5-PII-Anonymizer",
    "full_name": "AgenticA5/A5-PII-Anonymizer",
    "description": "Desktop App with Built-In LLM for Removing Personal Identifiable Information in Documents",
    "url": "https://github.com/AgenticA5/A5-PII-Anonymizer",
    "stars": 68,
    "daily_stars": 0,
    "language": "JavaScript",
    "topics": [
      "ai",
      "ai-safety",
      "alm",
      "anonymisation",
      "anonymity",
      "anonymization",
      "artificial-intelligence",
      "desktop-application",
      "electron",
      "electron-desktop",
      "gdpr",
      "hipaa",
      "linux",
      "llm",
      "macos",
      "personal-identifiable-information",
      "pii",
      "privacy",
      "reasoning",
      "windows"
    ],
    "created_at": "2025-02-17T22:10:04",
    "updated_at": "2025-02-22T12:44:57"
  },
  {
    "name": "Sentient",
    "full_name": "existence-master/Sentient",
    "description": "Your personal, private & interactive AI companion",
    "url": "https://github.com/existence-master/Sentient",
    "stars": 38,
    "daily_stars": 9,
    "language": "Python",
    "topics": [
      "agents",
      "artificial-intelligence",
      "automation",
      "local",
      "memory",
      "open-source",
      "personalization",
      "privacy"
    ],
    "created_at": "2025-02-20T04:33:41",
    "updated_at": "2025-02-23T08:25:09"
  },
  {
    "name": "II-OlimpiadaAI",
    "full_name": "OlimpiadaAI/II-OlimpiadaAI",
    "description": "Oficjalne repozytorium drugiej edycji og√≥lnopolskiej Olimpiady Sztucznej Inteligencji",
    "url": "https://github.com/OlimpiadaAI/II-OlimpiadaAI",
    "stars": 28,
    "daily_stars": 0,
    "language": "Jupyter Notebook",
    "topics": [
      "artificial-intelligence",
      "education",
      "high-school"
    ],
    "created_at": "2025-02-16T10:42:42",
    "updated_at": "2025-02-22T10:04:50"
  },
  {
    "name": "BoT",
    "full_name": "zihao-ai/BoT",
    "description": "Beak long thought processes of o1-like LLMs",
    "url": "https://github.com/zihao-ai/BoT",
    "stars": 18,
    "daily_stars": 0,
    "language": "Python",
    "topics": [
      "ai-agents",
      "backdoor-attacks",
      "chain-of-thought",
      "deepseek",
      "deepseek-r1",
      "large-language-models",
      "qwq",
      "reasoning-language-models"
    ],
    "created_at": "2025-02-17T08:09:39",
    "updated_at": "2025-02-21T09:13:12"
  },
  {
    "name": "HoST-pytorch",
    "full_name": "lucidrains/HoST-pytorch",
    "description": "Implementation of Humanoid Standing Up, from the paper \"Learning Humanoid Standing-up Control across Diverse Postures\" out of Shanghai, in Pytorch",
    "url": "https://github.com/lucidrains/HoST-pytorch",
    "stars": 17,
    "daily_stars": 0,
    "language": "Python",
    "topics": [
      "artificial-intelligence",
      "deep-learning",
      "humanoids",
      "reinforcement-learning",
      "reward-shaping"
    ],
    "created_at": "2025-02-16T15:30:01",
    "updated_at": "2025-02-20T06:40:03"
  },
  {
    "name": "HoST-pytorch",
    "full_name": "lucidrains/HoST-pytorch",
    "description": "Implementation of Humanoid Standing Up, from the paper \"Learning Humanoid Standing-up Control across Diverse Postures\" out of Shanghai, in Pytorch",
    "url": "https://github.com/lucidrains/HoST-pytorch",
    "stars": 17,
    "daily_stars": 0,
    "language": "Python",
    "topics": [
      "artificial-intelligence",
      "deep-learning",
      "humanoids",
      "reinforcement-learning",
      "reward-shaping"
    ],
    "created_at": "2025-02-16T15:30:01",
    "updated_at": "2025-02-20T06:40:03"
  }
]