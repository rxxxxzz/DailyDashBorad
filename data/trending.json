[
  {
    "name": "VVQuest",
    "full_name": "DanielZhangyc/VVQuest",
    "description": "智能检索张维为表情包",
    "url": "https://github.com/DanielZhangyc/VVQuest",
    "stars": 727,
    "daily_stars": 10,
    "language": "Python",
    "topics": [
      "artificial-intelligence",
      "embeddings-word2vec",
      "python",
      "streamlit",
      "streamlit-webapp"
    ],
    "created_at": "2025-02-11T13:28:11",
    "updated_at": "2025-02-25T16:26:04"
  },
  {
    "name": "native-sparse-attention-pytorch",
    "full_name": "lucidrains/native-sparse-attention-pytorch",
    "description": "Implementation of the sparse attention pattern proposed by the Deepseek team in their \"Native Sparse Attention\" paper",
    "url": "https://github.com/lucidrains/native-sparse-attention-pytorch",
    "stars": 463,
    "daily_stars": 3,
    "language": "Python",
    "topics": [
      "artificial-intelligence",
      "attention",
      "deep-learning"
    ],
    "created_at": "2025-02-19T03:37:52",
    "updated_at": "2025-02-25T16:43:54"
  },
  {
    "name": "laravel",
    "full_name": "grok-php/laravel",
    "description": "Seamlessly integrate Grok AI into Laravel applications with an elegant, developer-friendly package. Leverage powerful AI models for chat, automation, and NLP, while maintaining Laravel's expressive simplicity.",
    "url": "https://github.com/grok-php/laravel",
    "stars": 106,
    "daily_stars": 3,
    "language": "PHP",
    "topics": [
      "ai-api",
      "ai-assistant",
      "ai-powered-applications",
      "ai-sdk",
      "chatbot",
      "laravel",
      "laravel-ai",
      "machine-learning",
      "php-ai-sdk",
      "rest-api",
      "x-ai",
      "x-ai-grok",
      "x-ai-grok-2"
    ],
    "created_at": "2025-02-07T02:02:18",
    "updated_at": "2025-02-25T15:44:16"
  },
  {
    "name": "awesome-ai-ml-resources",
    "full_name": "armankhondker/awesome-ai-ml-resources",
    "description": "Learn AI/ML concepts and prepare for interviews using free resources.",
    "url": "https://github.com/armankhondker/awesome-ai-ml-resources",
    "stars": 2151,
    "daily_stars": 2,
    "language": null,
    "topics": [
      "artifical-intelligense",
      "computer-science",
      "deep-learning",
      "generative-ai",
      "machine-learning",
      "neural-networks",
      "python",
      "roadmap"
    ],
    "created_at": "2025-02-09T00:12:17",
    "updated_at": "2025-02-25T15:57:31"
  },
  {
    "name": "ai-guide",
    "full_name": "liyupi/ai-guide",
    "description": "鱼皮的 AI 知识库",
    "url": "https://github.com/liyupi/ai-guide",
    "stars": 97,
    "daily_stars": 1,
    "language": "Vue",
    "topics": [
      "ai",
      "algorithm",
      "artificial-intelligence",
      "chatgpt",
      "deep-learning",
      "deepseek",
      "deepseek-r1",
      "generative-ai",
      "gpt",
      "llm",
      "openai",
      "python",
      "vue",
      "vuepress"
    ],
    "created_at": "2025-02-13T05:47:46",
    "updated_at": "2025-02-25T15:52:04"
  },
  {
    "name": "deep-cross-attention",
    "full_name": "lucidrains/deep-cross-attention",
    "description": "Implementation of the proposed DeepCrossAttention by Heddes et al while at Google research, in Pytorch",
    "url": "https://github.com/lucidrains/deep-cross-attention",
    "stars": 76,
    "daily_stars": 1,
    "language": null,
    "topics": [
      "artificial-intelligence",
      "attention-mechanism",
      "deep-learning",
      "residuals",
      "transformers"
    ],
    "created_at": "2025-02-18T15:28:43",
    "updated_at": "2025-02-25T15:59:32"
  },
  {
    "name": "improving-transformers-world-model-for-rl",
    "full_name": "lucidrains/improving-transformers-world-model-for-rl",
    "description": "Implementation of the new SOTA for model based RL, from the paper \"Improving Transformer World Models for Data-Efficient RL\", in Pytorch",
    "url": "https://github.com/lucidrains/improving-transformers-world-model-for-rl",
    "stars": 63,
    "daily_stars": 1,
    "language": null,
    "topics": [
      "artificial-intelligence",
      "attention-mechanism",
      "deep-learning",
      "model-based-reinforcement-learning",
      "transformers",
      "world-models"
    ],
    "created_at": "2025-02-09T15:00:51",
    "updated_at": "2025-02-25T14:13:14"
  },
  {
    "name": "transformer-directed-evolution",
    "full_name": "lucidrains/transformer-directed-evolution",
    "description": "Explorations into whether a transformer with RL can direct a genetic algorithm to converge faster",
    "url": "https://github.com/lucidrains/transformer-directed-evolution",
    "stars": 61,
    "daily_stars": 1,
    "language": null,
    "topics": [
      "artificial-intelligence",
      "attention-mechanisms",
      "deep-learning",
      "evolutionary-algorithms",
      "reinforcement-learning"
    ],
    "created_at": "2025-02-01T14:54:41",
    "updated_at": "2025-02-25T14:13:36"
  },
  {
    "name": "transformer-lm-gan",
    "full_name": "lucidrains/transformer-lm-gan",
    "description": "Explorations into adversarial losses on top of autoregressive loss for language modeling",
    "url": "https://github.com/lucidrains/transformer-lm-gan",
    "stars": 33,
    "daily_stars": 1,
    "language": "Python",
    "topics": [
      "adversarial-learning",
      "artificial-intelligence",
      "autoregressive-transformers",
      "deep-learning"
    ],
    "created_at": "2025-02-14T14:56:14",
    "updated_at": "2025-02-25T16:00:20"
  },
  {
    "name": "ai-gateway",
    "full_name": "wx-yz/ai-gateway",
    "description": "Developer focused AI Gateway",
    "url": "https://github.com/wx-yz/ai-gateway",
    "stars": 8,
    "daily_stars": 1,
    "language": "Ballerina",
    "topics": [
      "ai",
      "ai-gateway",
      "artificial-intelligence",
      "docker",
      "llms"
    ],
    "created_at": "2025-02-14T01:52:54",
    "updated_at": "2025-02-25T16:10:06"
  }
]